{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOitQAwGLctcEa0KcddqUez",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smjenski-izvjestaji/izvjestaji/blob/main/source_kod.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1vsVZYiqhzk4",
        "outputId": "de780638-59a3-47e8-d1f3-31a671ac008f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.11/dist-packages (3.1.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.11/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.7.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "/bin/bash: line 1: https://smjenski-izvjestaji:${ secrets.GITHUB_TOKEN }@github.com/smjenski-izvjestaji/izvjestaji.git: bad substitution\n",
            "[Errno 2] No such file or directory: 'izvjestaji'\n",
            "/content\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-3865a74c-e62c-4040-acf4-8392b722b8e7\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-3865a74c-e62c-4040-acf4-8392b722b8e7\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Shift report template.xlsx to Shift report template (2).xlsx\n",
            "Processing line: RGB (Station ID: 1)\n",
            "âœ… Downloaded: Shift%20report%20template.xlsx\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "BadZipFile",
          "evalue": "File is not a zip file",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadZipFile\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3-3647245219.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;31m# ðŸ§  Step 3: Load workbook and sheet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;31m#filename = next(iter(uploaded))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mwb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_workbook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;31m#systime.sleep(10)  # Optional delay\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0msheet_814\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Sheet1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openpyxl/reader/excel.py\u001b[0m in \u001b[0;36mload_workbook\u001b[0;34m(filename, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \"\"\"\n\u001b[0;32m--> 346\u001b[0;31m     reader = ExcelReader(filename, read_only, keep_vba,\n\u001b[0m\u001b[1;32m    347\u001b[0m                          data_only, keep_links, rich_text)\n\u001b[1;32m    348\u001b[0m     \u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openpyxl/reader/excel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fn, read_only, keep_vba, data_only, keep_links, rich_text)\u001b[0m\n\u001b[1;32m    121\u001b[0m     def __init__(self, fn, read_only=False, keep_vba=KEEP_VBA,\n\u001b[1;32m    122\u001b[0m                  data_only=False, keep_links=True, rich_text=False):\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_validate_archive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalid_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marchive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamelist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openpyxl/reader/excel.py\u001b[0m in \u001b[0;36m_validate_archive\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     93\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mInvalidFileException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m     \u001b[0marchive\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marchive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps, metadata_encoding)\u001b[0m\n\u001b[1;32m   1311\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_RealGetContents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'w'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m                 \u001b[0;31m# set the modified flag so central directory gets written\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/zipfile.py\u001b[0m in \u001b[0;36m_RealGetContents\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1378\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mendrec\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1380\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mBadZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"File is not a zip file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mendrec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadZipFile\u001b[0m: File is not a zip file"
          ]
        }
      ],
      "source": [
        "# Step 1: Install required packages\n",
        "!pip install pandas openpyxl requests\n",
        "\n",
        "# Step 2: Upload the Excel template\n",
        "\n",
        "from google.colab import files\n",
        "#uploaded = files.upload()\n",
        "\n",
        "import pandas as pd\n",
        "import requests\n",
        "import base64\n",
        "import time as systime\n",
        "import ast\n",
        "from openpyxl import load_workbook\n",
        "from openpyxl.cell.cell import MergedCell\n",
        "from openpyxl.utils import get_column_letter\n",
        "from datetime import datetime, time\n",
        "from openpyxl.styles import Alignment, Font, Border  # remove when going back to .py version\n",
        "from copy import copy\n",
        "\n",
        "import requests\n",
        "\n",
        "from datetime import datetime, time\n",
        "from openpyxl import Workbook\n",
        "\n",
        "from datetime import datetime, time, timedelta\n",
        "from zoneinfo import ZoneInfo\n",
        "\n",
        "import textwrap\n",
        "import os\n",
        "import smtplib\n",
        "from email.message import EmailMessage\n",
        "\n",
        "\n",
        "import openpyxl\n",
        "from datetime import datetime\n",
        "from pathlib import Path\n",
        "import subprocess\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Station mapping\n",
        "station_map = {\"RGB\": 1, \"PET1\": 2, \"PET2\": 3}\n",
        "\n",
        "# Replace with your actual timezone (e.g., 'Europe/Belgrade', 'Europe/Zagreb')\n",
        "local_timezone = ZoneInfo('Europe/Zagreb')\n",
        "\n",
        "# Get local time\n",
        "now = datetime.utcnow()\n",
        "now_local = now.replace(tzinfo=ZoneInfo('UTC')).astimezone(local_timezone)\n",
        "\n",
        "current_time = now_local.time()\n",
        "\n",
        "# Determine shift and date based on local time\n",
        "# vrijeme je u UTC+0 by default a ne CEST (UTC+2) PAZI!!!\n",
        "# zato smo uveli now_local\n",
        "if time(5, 30) <= current_time < time(13, 30):\n",
        "    shift = 1\n",
        "    selected_date = now_local.date()\n",
        "elif time(13, 30) <= current_time < time(21, 30):\n",
        "    shift = 2\n",
        "    selected_date = now_local.date()\n",
        "else:\n",
        "    shift = 3\n",
        "    selected_date = (now_local - timedelta(days=1)).date()  # Use previous day\n",
        "\n",
        "# Format date for filename\n",
        "date_str = selected_date.strftime('%Y%m%d')\n",
        "\n",
        "#output_dir = Path(\"excel_reports\")\n",
        "#output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Iterate over each production line\n",
        "for line_input, station_id in station_map.items():\n",
        "    print(f\"Processing line: {line_input} (Station ID: {station_id})\")\n",
        "\n",
        "\n",
        "    # GitHub raw URL to the Excel template\n",
        "    template_url = \"https://raw.githubusercontent.com/smjenski-izvjestaji/izvjestaji/main/Shift_report_template.xlsx\"\n",
        "    filename = \"template.xlsx\"\n",
        "\n",
        "    # ðŸ“¥ Download the file\n",
        "    response = requests.get(template_url)\n",
        "    if response.status_code == 200:\n",
        "      with open(filename, 'wb') as f:\n",
        "          f.write(response.content)\n",
        "      print(f\"âœ… Template downloaded: {filename}\")\n",
        "    else:\n",
        "      raise Exception(f\"âŒ Failed to download file: {response.status_code}\")\n",
        "\n",
        "    # ðŸ§  Step 3: Load workbook and sheet\n",
        "    #filename = next(iter(uploaded))\n",
        "    wb = load_workbook(filename)\n",
        "    #systime.sleep(10)  # Optional delay\n",
        "    sheet_814 = wb['Sheet1']\n",
        "\n",
        "\n",
        "    # ðŸ” Step 4: Prepare API credentials\n",
        "    api_key = \"API_KEY\"         # ðŸ” Replace with your API key\n",
        "    secret_key = \"SECRET_KEY\"   # ðŸ” Replace with your secret key\n",
        "\n",
        "    credentials = f\"{api_key}:{secret_key}\"\n",
        "    encoded_credentials = base64.b64encode(credentials.encode()).decode()\n",
        "\n",
        "    headers = {\n",
        "    \"Authorization\": f\"Basic {encoded_credentials}\"\n",
        "    }\n",
        "\n",
        "    \"\"\"\n",
        "    # ðŸ­ Ask user for production line\n",
        "    line_input = input(\"Enter production line (PET1, PET2, or RGB): \").strip().upper().replace(\" \", \"\")\n",
        "    station_map = {\"RGB\": 1, \"PET1\": 2, \"PET2\": 3}\n",
        "\n",
        "    if line_input not in station_map:\n",
        "    raise ValueError(\"Invalid line. Use RGB, PET1, or PET2.\")\n",
        "\n",
        "    station_id = station_map[line_input]\n",
        "\n",
        "    # ðŸ“… Ask user for date\n",
        "    selected_date_input = input(\"Enter the date to retrieve checklists and stops (DD.MM.YYYY): \").strip()\n",
        "    try:\n",
        "        selected_date = datetime.strptime(selected_date_input, \"%d.%m.%Y\").date()\n",
        "    except ValueError:\n",
        "        raise ValueError(\"Invalid date format. Please use DD.MM.YYYY.\")\n",
        "\n",
        "\n",
        "    # ðŸ‘¥ Ask user for shift number\n",
        "    shift_input = input(\"Enter shift number (1, 2, or 3): \").strip()\n",
        "    if shift_input not in ['1', '2', '3']:\n",
        "        raise ValueError(\"Invalid shift. Please enter 1, 2, or 3.\")\n",
        "    shift = int(shift_input)\n",
        "    shift_label = {1: \"1st\", 2: \"2nd\", 3: \"3rd\"}[shift]\n",
        "    \"\"\"\n",
        "\n",
        "    # Station map\n",
        "    station_map = {\"RGB\": 1, \"PET1\": 2, \"PET2\": 3}\n",
        "    \"\"\"\n",
        "    # ðŸ“… Automatically use today's date\n",
        "    selected_date = datetime.today().date()\n",
        "\n",
        "    # â° Automatically determine shift based on current time\n",
        "    current_time = datetime.now().time()\n",
        "\n",
        "    if time(5, 30) <= current_time < time(13, 30):\n",
        "        shift = 1\n",
        "    elif time(13, 30) <= current_time < time(21, 30):\n",
        "        shift = 2\n",
        "    else:\n",
        "        shift = 3\n",
        "    \"\"\"\n",
        "    shift_label = {1: \"1st\", 2: \"2nd\", 3: \"3rd\"}[shift]\n",
        "\n",
        "\n",
        "    #  Define shift time windows for start and end\n",
        "    def get_shift_bounds(shift, date):\n",
        "        if shift == 1:\n",
        "            return time(5, 30), time(13, 30)\n",
        "        elif shift == 2:\n",
        "            return time(13, 30), time(21, 30)\n",
        "        elif shift == 3:\n",
        "            # Third shift spans 2 dates\n",
        "            return time(21, 30), time(5, 30)\n",
        "        else:\n",
        "            raise ValueError(\"Invalid shift number\")\n",
        "\n",
        "#\n",
        "    # ðŸ§¾ Write date and shift to cells D9 and F9\n",
        "    def set_left(cell, value):\n",
        "        cell.value = value\n",
        "        cell.alignment = Alignment(horizontal='left')\n",
        "\n",
        "    def set_left_font48(cell, value):\n",
        "        cell.value = value\n",
        "        cell.alignment = Alignment(horizontal='left')\n",
        "        cell.font = Font(name=\"Arial\", size=48)\n",
        "\n",
        "    def set_center(cell, value):\n",
        "        cell.value = value\n",
        "        cell.alignment = Alignment(horizontal='center')\n",
        "\n",
        "    def set_right(cell, value):\n",
        "        cell.value = value\n",
        "        cell.alignment = Alignment(horizontal='right')\n",
        "\n",
        "    set_left(sheet_814[\"D9\"], selected_date.strftime(\"%d.%m.%Y\"))\n",
        "    set_left(sheet_814[\"F9\"], str(shift))\n",
        "\n",
        "    # write other info in header (punjac, linija, ...)\n",
        "\n",
        "    if line_input == \"PET1\":\n",
        "        set_center(sheet_814[\"C6\"], \"PunjaÄ O+H\")\n",
        "        set_center(sheet_814[\"E6\"], \"PUNJENJE PET BOCA\")\n",
        "        set_center(sheet_814[\"Q6\"], \"LINIJA 866 (PET1)\")\n",
        "\n",
        "    elif line_input == \"PET2\":\n",
        "        set_center(sheet_814[\"C6\"], \"PunjaÄ Krones\")\n",
        "        set_center(sheet_814[\"E6\"], \"PUNJENJE PET BOCA\")\n",
        "        set_center(sheet_814[\"Q6\"], \"LINIJA 814 (PET2)\")\n",
        "\n",
        "    elif line_input == \"RGB\":\n",
        "        set_center(sheet_814[\"C6\"], \"PunjaÄ Krones\")\n",
        "        set_center(sheet_814[\"E6\"], \"PUNJENJE RGB BOCA\")\n",
        "        set_center(sheet_814[\"Q6\"], \"LINIJA 865 (RGB)\")\n",
        "\n",
        "\n",
        "\n",
        "    # ðŸ“¡ Step 5: Fetch checklist data from API\n",
        "    checklist_url = f\"https://api.evocon.com/api/reports/checklists_json?startTime=2025-03-01&endTime=2050-01-01&stationId={station_id}\"\n",
        "    response = requests.get(checklist_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Checklist API error: {response.status_code}\")\n",
        "\n",
        "    checklist_df = pd.DataFrame(response.json())\n",
        "\n",
        "    # ðŸ§¾ Step 6: Normalize checklist data\n",
        "    def clean_time(t):\n",
        "        if pd.isna(t): return None\n",
        "        t = str(t).replace(\":\", \"\").strip()\n",
        "        return t.zfill(4)[-4:]\n",
        "\n",
        "    # Handle stringified lists in 'itemresult'\n",
        "    def extract_single_value(x):\n",
        "        if isinstance(x, str) and x.startswith('[') and x.endswith(']'):\n",
        "            try:\n",
        "                parsed = ast.literal_eval(x)\n",
        "                if isinstance(parsed, list) and len(parsed) == 1:\n",
        "                    return str(parsed[0])\n",
        "            except:\n",
        "                return x\n",
        "        return str(x).strip()\n",
        "\n",
        "    checklist_df['clean_duetime'] = checklist_df['duetime'].apply(clean_time)\n",
        "    checklist_df['duetime_dt'] = pd.to_datetime(checklist_df['duetime'], format='%H:%M', errors='coerce').dt.time\n",
        "    checklist_df['date'] = pd.to_datetime(checklist_df['date'], errors='coerce').dt.date\n",
        "    checklist_df['itemname'] = checklist_df['itemname'].astype(str).str.strip().str.lower()\n",
        "    checklist_df['result'] = checklist_df['result'].astype(str).str.strip().str.lower()\n",
        "    checklist_df['itemresult'] = checklist_df['itemresult'].apply(extract_single_value)\n",
        "\n",
        "    # Apply shift filter\n",
        "    if shift == 1:\n",
        "        time_filter = (checklist_df['date'] == selected_date) & \\\n",
        "                      (checklist_df['duetime_dt'] >= time(6, 0)) & \\\n",
        "                      (checklist_df['duetime_dt'] <= time(14, 0))\n",
        "    elif shift == 2:\n",
        "        time_filter = (checklist_df['date'] == selected_date) & \\\n",
        "                      (checklist_df['duetime_dt'] > time(14, 0)) & \\\n",
        "                      (checklist_df['duetime_dt'] <= time(22, 0))\n",
        "    elif shift == 3:\n",
        "        next_day = selected_date + pd.Timedelta(days=1)\n",
        "        time_filter = (\n",
        "            ((checklist_df['date'] == selected_date) & (checklist_df['duetime_dt'] > time(22, 0))) |\n",
        "            ((checklist_df['date'] == next_day) & (checklist_df['duetime_dt'] <= time(5, 46)))\n",
        "        )\n",
        "\n",
        "    checklist_df = checklist_df[time_filter]\n",
        "\n",
        "    # Map parameter names from D17â€“D27\n",
        "    param_row_map = {}\n",
        "    for row in range(17, 28):\n",
        "        val = sheet_814[f\"D{row}\"].value\n",
        "        if val:\n",
        "            param_row_map[val.strip().lower()] = row\n",
        "\n",
        "    # Match headers in row 16\n",
        "    header_map = {}\n",
        "    for col in sheet_814.iter_cols(min_row=16, max_row=16):\n",
        "        cell = col[0]\n",
        "        if cell.value:\n",
        "            values = [p.strip().replace(\":\", \"\") for p in str(cell.value).split('/')]\n",
        "            if len(values) == 3:\n",
        "                header_map[col[0].column_letter] = {\n",
        "                    'morning': values[0].zfill(4),\n",
        "                    'afternoon': values[1].zfill(4),\n",
        "                    'night': values[2].zfill(4)\n",
        "                }\n",
        "\n",
        "    # Write checklist values\n",
        "    for _, row in checklist_df.iterrows():\n",
        "        if row['result'] != 'successful':\n",
        "            continue\n",
        "\n",
        "        param_name = row['itemname']\n",
        "        result = row['itemresult']\n",
        "        duetime = row['duetime_dt']\n",
        "        duetime_str = row['clean_duetime']\n",
        "\n",
        "        if pd.isna(duetime) or param_name not in param_row_map:\n",
        "            continue\n",
        "\n",
        "        shift_key = None\n",
        "        if time(6, 15) <= duetime <= time(13, 45):\n",
        "            shift_key = 'morning'\n",
        "        elif time(14, 15) <= duetime <= time(21, 45):\n",
        "            shift_key = 'afternoon'\n",
        "        elif duetime >= time(22, 15) or duetime <= time(5, 45):\n",
        "            shift_key = 'night'\n",
        "\n",
        "        target_column = None\n",
        "        for col_letter, shift_times in header_map.items():\n",
        "            if shift_times.get(shift_key) == duetime_str:\n",
        "                target_column = col_letter\n",
        "                break\n",
        "\n",
        "        if not target_column:\n",
        "            continue\n",
        "\n",
        "        row_number = param_row_map[param_name]\n",
        "        cell = sheet_814[f\"{target_column}{row_number}\"]\n",
        "        if not isinstance(cell, MergedCell):\n",
        "            set_left(cell, result)\n",
        "\n",
        "    # ðŸŒ API 2: Stop reasons\n",
        "    losses_url = f\"https://api.evocon.com/api/reports/losses_json?stationId={station_id}&startTime=2025-03-01&endTime=2050-01-01\"\n",
        "    response = requests.get(losses_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Losses API error: {response.status_code}\")\n",
        "\n",
        "    losses_df = pd.DataFrame(response.json())\n",
        "\n",
        "    losses_df['shiftStart'] = pd.to_datetime(losses_df['shiftStart'], errors='coerce')\n",
        "    losses_df['start'] = pd.to_datetime(losses_df['start'], errors='coerce')\n",
        "    losses_df['end'] = pd.to_datetime(losses_df['end'], errors='coerce')\n",
        "\n",
        "    filtered_losses = losses_df[\n",
        "        (losses_df['shiftStart'].dt.date == selected_date) &\n",
        "        (losses_df['shiftName'] == shift_label)\n",
        "    ]\n",
        "\n",
        "# Write stops to 814 starting from row 32\n",
        "# New scrit with joined stops\n",
        "\n",
        "    start_row = 32\n",
        "    processed_join_ids = set()\n",
        "\n",
        "    for idx, row in filtered_losses.iterrows():\n",
        "        join_id = row.get('stopJoinId')\n",
        "\n",
        "        if join_id and str(join_id).strip() != \"\":\n",
        "            if join_id in processed_join_ids:\n",
        "                continue\n",
        "            processed_join_ids.add(join_id)\n",
        "\n",
        "            # âœ… get full join group from losses_df (not just filtered)\n",
        "            group = losses_df[losses_df['stopJoinId'] == join_id].copy()\n",
        "            group = group.sort_values(by='start')\n",
        "\n",
        "            total_duration = 0\n",
        "            for _, sub in group.iterrows():\n",
        "                if pd.notna(sub['start']) and pd.notna(sub['end']):\n",
        "                    total_duration += (sub['end'] - sub['start']).total_seconds() / 60\n",
        "            total_duration = round(total_duration, 0)\n",
        "\n",
        "            location = group['location'].dropna().astype(str).str.strip().iloc[0] if not group['location'].dropna().empty else ''\n",
        "            stop_group = group['stopGroup'].dropna().astype(str).str.strip().iloc[0] if not group['stopGroup'].dropna().empty else ''\n",
        "            stop = str(group['stop'].iloc[0]).strip()\n",
        "            comment = str(group['comment'].iloc[0]).strip()\n",
        "            combined = f\"{stop} ({comment})\".strip()\n",
        "\n",
        "            if start_row >= 49:\n",
        "                sheet_814.insert_rows(start_row)\n",
        "\n",
        "                # ðŸ§½ Unmerge any cells that were auto-merged in the inserted row\n",
        "                for merged_range in list(sheet_814.merged_cells.ranges):\n",
        "                    if merged_range.min_row == start_row:\n",
        "                        try:\n",
        "                            sheet_814.unmerge_cells(str(merged_range))\n",
        "                        except KeyError:\n",
        "                            pass # merged cell may already have been cleared\n",
        "\n",
        "                # ðŸŽ¨ Copy style from row 49 to the new row\n",
        "\n",
        "                for col in range(1, sheet_814.max_column + 1):\n",
        "                    source_cell = sheet_814.cell(row=49, column=col)\n",
        "                    target_cell = sheet_814.cell(row=start_row, column=col)\n",
        "\n",
        "                    # Copy formatting if any\n",
        "                    if source_cell.has_style:\n",
        "                        target_cell.font = copy(source_cell.font)\n",
        "                        target_cell.border = copy(source_cell.border)\n",
        "                        target_cell.fill = source_cell.fill\n",
        "                        target_cell.number_format = source_cell.number_format\n",
        "                        target_cell.protection = source_cell.protection\n",
        "                        target_cell.alignment = source_cell.alignment\n",
        "\n",
        "                # Set row height for larger font\n",
        "                sheet_814.row_dimensions[start_row].height = 90\n",
        "\n",
        "\n",
        "            set_left_font48(sheet_814[f\"E{start_row}\"], \"joined stops\")\n",
        "            set_left_font48(sheet_814[f\"F{start_row}\"], \"joined stops\")\n",
        "            set_left_font48(sheet_814[f\"G{start_row}\"], total_duration)\n",
        "            set_left_font48(sheet_814[f\"H{start_row}\"], location)\n",
        "            set_left_font48(sheet_814[f\"K{start_row}\"], stop_group)\n",
        "            set_left_font48(sheet_814[f\"N{start_row}\"], combined)\n",
        "\n",
        "            start_row += 1\n",
        "\n",
        "        else:\n",
        "            # âœ… true individual stop (no join ID or empty)\n",
        "            if start_row >= 49:\n",
        "                sheet_814.insert_rows(start_row)\n",
        "\n",
        "                # ðŸ§½ Unmerge any cells that were auto-merged in the inserted row\n",
        "                for merged_range in list(sheet_814.merged_cells.ranges):\n",
        "                    if merged_range.min_row == start_row:\n",
        "                        try:\n",
        "                            sheet_814.unmerge_cells(str(merged_range))\n",
        "                        except KeyError:\n",
        "                            pass # merged cell may already have been cleared\n",
        "\n",
        "            # ðŸŽ¨ Copy style from row 49 to the new row\n",
        "                for col in range(1, sheet_814.max_column + 1):\n",
        "                    source_cell = sheet_814.cell(row=49, column=col)\n",
        "                    target_cell = sheet_814.cell(row=start_row, column=col)\n",
        "\n",
        "                    # Copy formatting if any\n",
        "                    if source_cell.has_style:\n",
        "                        target_cell.font = copy(source_cell.font)\n",
        "                        target_cell.border = copy(source_cell.border)\n",
        "                        target_cell.fill = copy(source_cell.fill)\n",
        "                        target_cell.number_format = copy(source_cell.number_format)\n",
        "                        target_cell.protection = copy(source_cell.protection)\n",
        "                        target_cell.alignment = copy(source_cell.alignment)\n",
        "\n",
        "                # Set row height for larger font\n",
        "                sheet_814.row_dimensions[start_row].height = 90\n",
        "\n",
        "            start_time = row['start'].strftime('%H:%M') if pd.notna(row['start']) else ''\n",
        "            end_time = row['end'].strftime('%H:%M') if pd.notna(row['end']) else ''\n",
        "            duration = ''\n",
        "            if pd.notna(row['start']) and pd.notna(row['end']):\n",
        "                duration = (row['end'] - row['start']).total_seconds() / 60\n",
        "                duration = round(duration, 0)\n",
        "\n",
        "            location = str(row.get('location', '')).strip()\n",
        "            stop_group = str(row.get('stopGroup', '')).strip()\n",
        "            stop = str(row.get('stop', '')).strip()\n",
        "            comment = str(row.get('comment', '')).strip()\n",
        "            combined = f\"{stop} ({comment})\".strip()\n",
        "\n",
        "            set_left_font48(sheet_814[f\"E{start_row}\"], start_time)\n",
        "            set_left_font48(sheet_814[f\"F{start_row}\"], end_time)\n",
        "            set_left_font48(sheet_814[f\"G{start_row}\"], duration)\n",
        "            set_left_font48(sheet_814[f\"H{start_row}\"], location)\n",
        "            set_left_font48(sheet_814[f\"K{start_row}\"], stop_group)\n",
        "            set_left_font48(sheet_814[f\"N{start_row}\"], combined)\n",
        "\n",
        "            start_row += 1\n",
        "\n",
        "    # ðŸ” Speed losses API\n",
        "    speed_url = f\"https://api.evocon.com/api/reports/speedlosses_json?stationId={station_id}&startTime=2025-03-01&endTime=2050-01-01\"\n",
        "    response = requests.get(speed_url, headers=headers)\n",
        "    if response.status_code != 200:\n",
        "        raise Exception(f\"Speed losses API error: {response.status_code}\")\n",
        "\n",
        "    speed_df = pd.DataFrame(response.json())\n",
        "    speed_df['start'] = pd.to_datetime(speed_df['start'], errors='coerce')\n",
        "    speed_df['shiftName'] = speed_df['shiftName'].astype(str).str.strip()\n",
        "    speed_df['performanceLossNotes'] = speed_df['performanceLossNotes'].astype(str).fillna('').str.strip()\n",
        "    speed_df['stopMinutes'] = pd.to_numeric(speed_df['stopMinutes'], errors='coerce').fillna(0)\n",
        "\n",
        "    # Filter by selected date and shift\n",
        "    if shift == 3:\n",
        "        next_day = selected_date + pd.Timedelta(days=1)\n",
        "        speed_filtered = speed_df[\n",
        "            ((speed_df['start'].dt.date == selected_date) & (speed_df['start'].dt.time > time(21, 30))) |\n",
        "            ((speed_df['start'].dt.date == next_day) & (speed_df['start'].dt.time <= time(5, 30)))\n",
        "        ]\n",
        "    else:\n",
        "        speed_filtered = speed_df[\n",
        "            (speed_df['start'].dt.date == selected_date) &\n",
        "            (speed_df['shiftName'] == shift_label)\n",
        "        ]\n",
        "\n",
        "    # Group by comment (performanceLossNotes)\n",
        "    grouped_speed = speed_filtered.groupby('performanceLossNotes')\n",
        "\n",
        "    for comment, group in grouped_speed:\n",
        "        total_duration = round(group['stopMinutes'].sum(), 0)\n",
        "\n",
        "        if start_row >= 49:\n",
        "            sheet_814.insert_rows(start_row)\n",
        "            for merged_range in list(sheet_814.merged_cells.ranges):\n",
        "                if merged_range.min_row == start_row:\n",
        "                    try:\n",
        "                        sheet_814.unmerge_cells(str(merged_range))\n",
        "                    except KeyError:\n",
        "                        pass\n",
        "            for col in range(1, sheet_814.max_column + 1):\n",
        "                source_cell = sheet_814.cell(row=49, column=col)\n",
        "                target_cell = sheet_814.cell(row=start_row, column=col)\n",
        "                if source_cell.has_style:\n",
        "                    target_cell.font = copy(source_cell.font)\n",
        "                    target_cell.border = copy(source_cell.border)\n",
        "                    target_cell.fill = copy(source_cell.fill)\n",
        "                    target_cell.number_format = copy(source_cell.number_format)\n",
        "                    target_cell.protection = copy(source_cell.protection)\n",
        "                    target_cell.alignment = copy(source_cell.alignment)\n",
        "\n",
        "        # Write values to sheet\n",
        "        set_left(sheet_814[f\"E{start_row}\"], \"gubitak brzine\")\n",
        "        set_left(sheet_814[f\"F{start_row}\"], \"gubitak brzine\")\n",
        "        set_left(sheet_814[f\"G{start_row}\"], total_duration)\n",
        "        set_left(sheet_814[f\"K{start_row}\"], \"gubitak brzine\")\n",
        "        set_left(sheet_814[f\"N{start_row}\"], comment)\n",
        "\n",
        "        start_row += 1\n",
        "\n",
        "\n",
        "\n",
        "    # ðŸš€ STEP: Fill product info (product name, SKU, start/end time of runs) into Sheet1\n",
        "\n",
        "\n",
        "    # ðŸ§© 1. Get shift time boundaries\n",
        "    shift_start_time, shift_end_time = get_shift_bounds(shift, selected_date)\n",
        "\n",
        "    # ðŸ‘€ 2. Get first product info from the first stop\n",
        "    first_stop_row = filtered_losses.iloc[0]\n",
        "    first_product_name = str(first_stop_row.get(\"productName\", \"\")).strip()\n",
        "    first_product_sku = str(first_stop_row.get(\"productSku\", \"\")).strip()\n",
        "\n",
        "    # ðŸ–‹ï¸ Fill F10 (SKU), F11 (product), and J10 (shift start time) initially\n",
        "    sheet_814[\"F10\"].value = first_product_sku\n",
        "    sheet_814[\"F11\"].value = first_product_name\n",
        "    sheet_814[\"J10\"].value = shift_start_time.strftime(\"%H:%M\")\n",
        "\n",
        "    # â³ 3. Fetch production runs and filter those within this shift\n",
        "    prod_url = f\"https://api.evocon.com/api/reports/production_runs_json?startTime=2025-03-01&endTime=2050-01-01&stationId={station_id}\"\n",
        "    prod_df = pd.DataFrame(requests.get(prod_url, headers=headers).json())\n",
        "\n",
        "    # Normalize times and dates\n",
        "    prod_df['startDate'] = pd.to_datetime(prod_df['startDate'], errors='coerce').dt.date\n",
        "    prod_df['startTime'] = pd.to_datetime(prod_df['startTime'], errors='coerce')\n",
        "    prod_df['endTime'] = pd.to_datetime(prod_df['endTime'], errors='coerce')\n",
        "\n",
        "    # For 3rd shift, we must span dates\n",
        "    if shift == 3:\n",
        "        next_day = selected_date + pd.Timedelta(days=1)\n",
        "        shift_filter = (\n",
        "            ((prod_df['startDate'] == selected_date) & (prod_df['startTime'].dt.time >= shift_start_time)) |\n",
        "            ((prod_df['startDate'] == next_day) & (prod_df['startTime'].dt.time <= shift_end_time))\n",
        "        )\n",
        "    else:\n",
        "        shift_filter = (\n",
        "            (prod_df['startDate'] == selected_date) &\n",
        "            (prod_df['startTime'].dt.time >= shift_start_time) &\n",
        "            (prod_df['startTime'].dt.time <= shift_end_time)\n",
        "        )\n",
        "\n",
        "    prod_filtered = prod_df[shift_filter].sort_values(by=\"startTime\").reset_index(drop=True)\n",
        "\n",
        "    # ðŸ§  4. Build initial production run list from stop data\n",
        "    production_runs = [{\n",
        "        \"sku\": first_product_sku,\n",
        "        \"product\": first_product_name,\n",
        "        \"start_time\": shift_start_time.strftime(\"%H:%M\"),\n",
        "        \"end_time\": None  # to be filled later\n",
        "    }]\n",
        "\n",
        "    # ðŸ” 5. Detect \"Changeover and CIP\" stops to determine end/start transitions\n",
        "    changeover_rows = filtered_losses[filtered_losses[\"stopGroup\"] == \"Changeover and CIP\"].copy()\n",
        "    changeover_rows = changeover_rows.sort_values(by=\"start\").reset_index(drop=True)\n",
        "\n",
        "    # Assign end time of first run\n",
        "    if not changeover_rows.empty and pd.notna(changeover_rows.iloc[0][\"start\"]):\n",
        "        production_runs[0][\"end_time\"] = changeover_rows.iloc[0][\"start\"].strftime(\"%H:%M\")\n",
        "    else:\n",
        "        production_runs[0][\"end_time\"] = shift_end_time.strftime(\"%H:%M\")\n",
        "\n",
        "\n",
        "    # ðŸ” 6. Append production runs from prod_filtered (with proper changeover sequencing)\n",
        "    changeover_rows = changeover_rows.reset_index(drop=True)  # Safe for iloc\n",
        "    all_stops = filtered_losses.reset_index(drop=True)        # Ensure same for full stops list\n",
        "\n",
        "    changeover_idx = 0\n",
        "    last_valid_end = None\n",
        "\n",
        "    for i, row in prod_filtered.iterrows():\n",
        "        sku = str(row.get(\"sku\", \"\")).strip()\n",
        "        product = str(row.get(\"product\", \"\")).strip()\n",
        "\n",
        "        # ðŸ§© Find the last \"Changeover and CIP\" in a consecutive sequence\n",
        "        cip_end_time = None\n",
        "        while changeover_idx < len(changeover_rows):\n",
        "            current_cip = changeover_rows.iloc[changeover_idx]\n",
        "            changeover_idx += 1\n",
        "\n",
        "            # If last or next stop is not \"Changeover and CIP\", this is the last in sequence\n",
        "            if changeover_idx == len(changeover_rows):\n",
        "                cip_end_time = current_cip.get(\"end\")\n",
        "                break\n",
        "\n",
        "            next_cip = changeover_rows.iloc[changeover_idx]\n",
        "            curr_idx_in_all = all_stops[all_stops['start'] == current_cip['start']].index[0]\n",
        "\n",
        "            if curr_idx_in_all + 1 < len(all_stops):\n",
        "                next_stop_group = all_stops.iloc[curr_idx_in_all + 1].get(\"stopGroup\", \"\")\n",
        "                if next_stop_group != \"Changeover and CIP\":\n",
        "                    cip_end_time = current_cip.get(\"end\")\n",
        "                    break\n",
        "\n",
        "        # ðŸ•’ Start time = end of last CIP, or start of shift\n",
        "        if pd.notna(cip_end_time):\n",
        "            start_time = cip_end_time\n",
        "        else:\n",
        "            start_time = row.get(\"startTime\") or shift_start_time\n",
        "\n",
        "        start_str = start_time.strftime(\"%H:%M\") if pd.notna(start_time) else \"\"\n",
        "\n",
        "        # ðŸ•› End time = next CIP start, or shift end\n",
        "        if changeover_idx < len(changeover_rows):\n",
        "            next_cip_start = changeover_rows.iloc[changeover_idx][\"start\"]\n",
        "            end_str = next_cip_start.strftime(\"%H:%M\") if pd.notna(next_cip_start) else shift_end_time.strftime(\"%H:%M\")\n",
        "        else:\n",
        "            end_str = shift_end_time.strftime(\"%H:%M\")\n",
        "\n",
        "        production_runs.append({\n",
        "            \"sku\": sku,\n",
        "            \"product\": product,\n",
        "            \"start_time\": start_str,\n",
        "            \"end_time\": end_str\n",
        "        })\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #version of insert rows and writing with font and size formatting and with row height adjustment\n",
        "\n",
        "\n",
        "    # ðŸ”  Font config\n",
        "    prod_font = Font(name=\"Arial\", size=48)\n",
        "    bold_font = Font(bold=True)\n",
        "\n",
        "    # ðŸ§± Insert new rows (if more than one product)\n",
        "    insert_point = 10\n",
        "    extra_runs = len(production_runs) - 1\n",
        "\n",
        "    if extra_runs > 0:\n",
        "        for _ in range(extra_runs * 2):\n",
        "            sheet_814.insert_rows(insert_point)\n",
        "\n",
        "    # ðŸ§¾ content to be written in new cells inserted\n",
        "    title_map = {\n",
        "        \"E\": \"Å ifra:\",\n",
        "        \"E_lower\": \"Naziv proizvoda:\",\n",
        "        \"H\": \"Proizvodnja od (prva boca kontinuirano na punjaÄu):\",\n",
        "        \"H_lower\": \"Proizvodnja do (zadnja boca na punjaÄu):\",\n",
        "    }\n",
        "\n",
        "    # ðŸ§¬ Apply values and formatting row by row\n",
        "    for i, run in enumerate(production_runs):\n",
        "        row_top = 10 + (i * 2)\n",
        "        row_bottom = row_top + 1\n",
        "\n",
        "        # Copy titles to column E and H\n",
        "        sheet_814[f\"E{row_top}\"].value = title_map[\"E\"]\n",
        "        sheet_814[f\"E{row_bottom}\"].value = title_map[\"E_lower\"]\n",
        "        sheet_814[f\"H{row_top}\"].value = title_map[\"H\"]\n",
        "        sheet_814[f\"H{row_bottom}\"].value = title_map[\"H_lower\"]\n",
        "\n",
        "        for col in ['E', 'F', 'H', 'J']:\n",
        "            for r in [row_top, row_bottom]:\n",
        "                cell = sheet_814[f\"{col}{r}\"]\n",
        "                cell.font = prod_font\n",
        "                cell.alignment = Alignment(horizontal='left', wrap_text=True)\n",
        "\n",
        "        # Fill values for product info\n",
        "        set_left(sheet_814[f\"F{row_top}\"], run[\"sku\"])\n",
        "        set_left(sheet_814[f\"F{row_bottom}\"], run[\"product\"])\n",
        "        set_left(sheet_814[f\"J{row_top}\"], run[\"start_time\"])\n",
        "        set_left(sheet_814[f\"J{row_bottom}\"], run[\"end_time\"])\n",
        "        # ovdje je u og kodu bilo height = 159\n",
        "        # Dynamically adjust row height based on the maximum number of lines in the cells\n",
        "        def get_max_lines(row_num, columns):\n",
        "            max_lines = 1\n",
        "            for col in columns:\n",
        "                cell_value = str(sheet_814[f\"{col}{row_num}\"].value or \"\")\n",
        "                lines = cell_value.count('\\n') + 1\n",
        "                max_lines = max(max_lines, lines)\n",
        "            return max_lines\n",
        "\n",
        "        font_size = prod_font.size if hasattr(prod_font, 'size') else 12\n",
        "        line_height = font_size * 1.2  # Approximate line height\n",
        "        for r in [row_top, row_bottom]:\n",
        "            max_lines = get_max_lines(r, ['E', 'F', 'H', 'J'])\n",
        "            sheet_814.row_dimensions[r].height = max(30, int(line_height * max_lines))\n",
        "\n",
        "    # Automatically adjust row height to fit all text\n",
        "    #for r in [row_top, row_bottom]:\n",
        "     #   max_height = 15  # minimum height\n",
        "      #  for col in ['E', 'F', 'H', 'J']:\n",
        "       #     cell = sheet_814[f\"{col}{r}\"]\n",
        "        #    if cell.value:\n",
        "                # Estimate height: 1.2x font size per line, count lines by splitting on '\\n'\n",
        "         #       lines = str(cell.value).split('\\n')\n",
        "          #      num_lines = max(len(lines), 1)\n",
        "           ##    max_height = max(max_height, height)\n",
        "        #sheet_814.row_dimensions[r].height = max_height\n",
        "\n",
        "\n",
        "    header = 30 #gornja sastavnica\n",
        "    footer = 6 #doljnja sastavnica\n",
        "\n",
        "    def make_header(from_sheet, header_rows):\n",
        "    #from_sheet se samo referira na sheet excela\n",
        "    # postavljanje headera kao rows\n",
        "        from_sheet.print_title_rows = f'1:{header_rows}'\n",
        "\n",
        "# mozda bi radilo da u taj length dodam AND raspon footera al idk bi li slomilo kod\n",
        "\n",
        "    def make_footer(from_sheet, footer_rows):\n",
        "        max_row = from_sheet.max_row\n",
        "        footer_texts = []\n",
        "        for row in range(max_row - footer_rows, max_row + 1):\n",
        "            row_values = []\n",
        "            for col in range(1, from_sheet.max_column + 1):\n",
        "                cell = from_sheet.cell(row=row, column=col)\n",
        "                if cell.value:\n",
        "                    row_values.append(str(cell.value))\n",
        "            if row_values:\n",
        "                footer_texts.append(\" | \".join(row_values))\n",
        "        # pretvori sve u string jer excel supporta samo string footers iz nekog razloga\n",
        "        footer_str = \"\\n\".join(footer_texts)\n",
        "        # Set footer font explicitly to Arial, size 48\n",
        "        font_str = '&\"Arial\"&48'\n",
        "        formatted_footer = f'{font_str}{footer_str}'\n",
        "        from_sheet.oddFooter.center.text = formatted_footer\n",
        "\n",
        "    make_header(sheet_814, header)\n",
        "    # make_footer(sheet_814, footer)\n",
        "\n",
        "    # ðŸ’¾ Step 11: Save and download\n",
        "    from openpyxl.utils import get_column_letter\n",
        "\n",
        "# namjesti print area na cijeli range\n",
        "# jer ako netko ne klikne \"ignore print range\" pri printanju\n",
        "# nece iskopirati sve redove\n",
        "    max_row = sheet_814.max_row\n",
        "    max_col = sheet_814.max_column\n",
        "    print_area = f\"A1:{get_column_letter(max_col)}{max_row}\"\n",
        "    sheet_814.print_area = print_area\n",
        "\n",
        "\n",
        "    #output_file = output_dir / f\"updated_shift_report_{line_input}_{date_str}.xlsx\"\n",
        "    #wb.save(output_file)\n",
        "\n",
        "    # Define the output directory\n",
        "    output_dir = \"excel_reports\"\n",
        "\n",
        "    # Create the folder if it doesn't exist\n",
        "    if not os.path.exists(output_dir):\n",
        "      os.makedirs(output_dir)\n",
        "\n",
        "    # Save the Excel file\n",
        "    output_file = f\"{output_dir}/updated_shift_report_{line_input}_{date_str}.xlsx\"\n",
        "    wb.save(output_file)\n",
        "\n",
        "    #wb.save(full_path)\n",
        "    #wb.save(output_file)\n",
        "    #files.download(output_file)\n",
        "    \"\"\"\n",
        "        # Git commit and push\n",
        "    try:\n",
        "      print(\"---GIT ADD---\")\n",
        "      subprocess.run([\"git\", \"add\", str(full_path)], check=True, capture_output=True, text=True)\n",
        "      print(\"---GIT COMMIT---\")\n",
        "      subprocess.run([\"git\", \"commit\", \"-m\", f\"Add Excel file {filename}\"], check=True, capture_output=True, text=True)\n",
        "      print(\"---GIT PUSH---\")\n",
        "      subprocess.run([\"git\", \"push\"], check=True, capture_output=True, text=True)\n",
        "      print(\"âœ… Excel file committed and pushed to GitHub.\")\n",
        "    except subprocess.CalledProcessError as e:\n",
        "      print(f\"âŒ Git operation failed: {e}\")\n",
        "      print(f\"---STDOUT---:\\n{e.stdout}\")\n",
        "      print(f\"---STDERR---:\\n{e.stderr}\")\n",
        "    \"\"\""
      ]
    }
  ]
}